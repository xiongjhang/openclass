{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_num_parameters(model: nn.Module) -> int:\n",
    "    return sum(param.numel() for param in model.parameters())\n",
    "\n",
    "def get_device(index: int = 0) -> torch.device:\n",
    "    \"\"\"Try to use the GPU if possible, otherwise, use CPU.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(f\"cuda:{index}\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moule Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16384\n",
    "output_dim = 32\n",
    "\n",
    "w = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "assert isinstance(w, torch.Tensor)  # Behaves like a tensor\n",
    "assert type(w.data) == torch.Tensor  # Access the underlying tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    \"\"\"Simple linear layer.\"\"\"\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x @ self.weight\n",
    "    \n",
    "class Cruncher(nn.Module):\n",
    "    def __init__(self, dim: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Linear(dim, dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.final = Linear(dim, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply linear layers\n",
    "        B, D = x.size()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Apply final head\n",
    "        x = self.final(x)\n",
    "        assert x.size() == torch.Size([B, 1])\n",
    "\n",
    "        # Remove the last dimension\n",
    "        x = x.squeeze(-1)\n",
    "        assert x.size() == torch.Size([B])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "D = 64  # Dimension\n",
    "num_layers = 2\n",
    "model = Cruncher(dim=D, num_layers=num_layers)\n",
    "\n",
    "param_sizes = [\n",
    "    (name, param.numel())\n",
    "    for name, param in model.state_dict().items()\n",
    "]\n",
    "assert param_sizes == [\n",
    "    (\"layers.0.weight\", D * D),\n",
    "    (\"layers.1.weight\", D * D),\n",
    "    (\"final.weight\", D),\n",
    "]\n",
    "num_parameters = get_num_parameters(model)\n",
    "assert num_parameters == (D * D) + (D * D) + D\n",
    "\n",
    "# Remember to move the model to the GPU.\n",
    "device = get_device()\n",
    "model = model.to(device)\n",
    "\n",
    "# Run the model on some data.\n",
    "B = 8  # Batch size\n",
    "x = torch.randn(B, D, device=device)\n",
    "y = model(x)\n",
    "assert y.size() == torch.Size([B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note about Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three places to set the random seed which you should do all at once just to be safe.\n",
    "# Torch\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Python\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131891/481296123.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1699449181081/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  x = torch.tensor([data[start:start + sequence_length] for start in start_indices])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data: np.array, batch_size: int, sequence_length: int, device: str) -> torch.Tensor:\n",
    "    # Sample batch_size random positions into data.\n",
    "    start_indices = torch.randint(len(data) - sequence_length, (batch_size,))\n",
    "    assert start_indices.size() == torch.Size([batch_size])\n",
    "\n",
    "    # Index into the data.\n",
    "    x = torch.tensor([data[start:start + sequence_length] for start in start_indices])\n",
    "    assert x.size() == torch.Size([batch_size, sequence_length])\n",
    "\n",
    "    # Pinned memory\n",
    "    # By default, CPU tensors are in paged memory. We can explicitly pin.\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.pin_memory()\n",
    "    # This allows us to copy x from CPU into GPU asynchronously.\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    # This allows us to do two things in parallel (not done here):\n",
    "    # 1. Fetch the next batch of data into CPU\n",
    "    # 2. Process x on the GPU.\n",
    "\n",
    "    return x\n",
    "\n",
    "# serialization\n",
    "orig_data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.int32)\n",
    "orig_data.tofile(\"data.npy\")\n",
    "\n",
    "# loading\n",
    "# Use memmap to lazily load only the accessed parts into memory.\n",
    "data = np.memmap(\"data.npy\", dtype=np.int32)\n",
    "assert np.array_equal(data, orig_data)\n",
    "\n",
    "# A data loader generates a batch of sequences for training.\n",
    "B = 2  # Batch size\n",
    "L = 4  # Length of sequence\n",
    "x = get_batch(data, batch_size=B, sequence_length=L, device=get_device())\n",
    "assert x.size() == torch.Size([B, L])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(torch.optim.Optimizer):\n",
    "    def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01):\n",
    "        super(SGD, self).__init__(params, dict(lr=lr))\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"]\n",
    "            for p in group[\"params\"]:\n",
    "                grad = p.grad.data\n",
    "                p.data -= lr * grad\n",
    "                \n",
    "                \n",
    "class AdaGrad(torch.optim.Optimizer):\n",
    "    def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01):\n",
    "        super(AdaGrad, self).__init__(params, dict(lr=lr))\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"]\n",
    "            for p in group[\"params\"]:\n",
    "                # Optimizer state\n",
    "                state = self.state[p]\n",
    "                grad = p.grad.data\n",
    "\n",
    "                # Get squared gradients g2 = sum_{i<t} g_i^2\n",
    "                g2 = state.get(\"g2\", torch.zeros_like(grad))\n",
    "\n",
    "                # Update optimizer state\n",
    "                g2 += torch.square(grad)\n",
    "                state[\"g2\"] = g2\n",
    "                \n",
    "                # Update parameters\n",
    "                p.data -= lr * grad / torch.sqrt(g2 + 1e-5)\n",
    "\n",
    "# recall deep linear model\n",
    "B = 2\n",
    "D = 4\n",
    "num_layers = 2\n",
    "model = Cruncher(dim=D, num_layers=num_layers).to(get_device())\n",
    "\n",
    "optimizer = AdaGrad(model.parameters(), lr=0.01)\n",
    "state = model.state_dict()  # @inspect state\n",
    "\n",
    "# Compute gradients\n",
    "x = torch.randn(B, D, device=get_device())\n",
    "y = torch.tensor([4., 5.], device=get_device())\n",
    "pred_y = model(x)\n",
    "loss = F.mse_loss(input=pred_y, target=y)\n",
    "loss.backward()\n",
    "\n",
    "# Take a step\n",
    "optimizer.step()\n",
    "state = model.state_dict()  # @inspect state\n",
    "\n",
    "# Free up the memory (optional)\n",
    "optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory\n",
    "# Parameters\n",
    "num_parameters = (D * D * num_layers) + D  # @inspect num_parameters\n",
    "assert num_parameters == get_num_parameters(model)\n",
    "\n",
    "# Activations\n",
    "num_activations = B * D * num_layers  # @inspect num_activations\n",
    "\n",
    "# Gradients\n",
    "num_gradients = num_parameters  # @inspect num_gradients\n",
    "\n",
    "# Optimizer states\n",
    "num_optimizer_states = num_parameters  # @inspect num_optimizer_states\n",
    "\n",
    "# Putting it all together, assuming float32\n",
    "total_memory = 4 * (num_parameters + num_activations + num_gradients + num_optimizer_states)  # @inspect total_memory\n",
    "\n",
    "# Compute (for one step)\n",
    "flops = 6 * B * num_parameters  # @inspect flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 1292.5894, \n",
      "Step 1, Loss: 1166.7372, \n",
      "Step 2, Loss: 1209.9089, \n",
      "Step 3, Loss: 1480.7728, \n",
      "Step 4, Loss: 1109.9225, \n",
      "Step 5, Loss: 906.7762, \n",
      "Step 6, Loss: 479.8622, \n",
      "Step 7, Loss: 425.7617, \n",
      "Step 8, Loss: 919.3986, \n",
      "Step 9, Loss: 3253.2998, \n"
     ]
    }
   ],
   "source": [
    "def train(name: str, get_batch,\n",
    "          D: int, num_layers: int,\n",
    "          B: int, num_train_steps: int, lr: float):\n",
    "    model = Cruncher(dim=D, num_layers=0).to(get_device())\n",
    "    optimizer = SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for t in range(num_train_steps):\n",
    "        # Get data\n",
    "        x, y = get_batch(B=B)\n",
    "\n",
    "        # Forward (compute loss)\n",
    "        pred_y = model(x)\n",
    "        loss = F.mse_loss(pred_y, y)\n",
    "\n",
    "        print(f\"Step {t}, Loss: {loss.item():.4f}, \")\n",
    "\n",
    "        # Backward (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "D = 16\n",
    "true_w = torch.arange(D, dtype=torch.float32, device=get_device())\n",
    "def get_batch(B: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x = torch.randn(B, D).to(get_device())\n",
    "    true_y = x @ true_w\n",
    "    return (x, true_y)\n",
    "\n",
    "# Let's do a basic run\n",
    "train(\"simple\", get_batch, D=D, num_layers=0, B=4, num_train_steps=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 1160.1960, \n",
      "Step 1, Loss: 584.6788, \n",
      "Step 2, Loss: 682.3929, \n",
      "Step 3, Loss: 542.1847, \n",
      "Step 4, Loss: 1326.8734, \n",
      "Step 5, Loss: 517.3848, \n",
      "Step 6, Loss: 600.0370, \n",
      "Step 7, Loss: 3213.6191, \n",
      "Step 8, Loss: 2038.8077, \n",
      "Step 9, Loss: 208.5746, \n"
     ]
    }
   ],
   "source": [
    "# Do some hyperparameter tuning\n",
    "train(\"simple\", get_batch, D=D, num_layers=0, B=4, num_train_steps=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cruncher(dim=64, num_layers=3).to(get_device())\n",
    "optimizer = AdaGrad(model.parameters(), lr=0.01)\n",
    "\n",
    "# save the checkpoint\n",
    "checkpoint = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, \"model_checkpoint.pt\")\n",
    "\n",
    "# load the checkpoint\n",
    "loaded_checkpoint = torch.load(\"model_checkpoint.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
